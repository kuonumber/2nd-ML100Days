# 2nd-ML100Days

## D2
  * [basic pandas](https://bookdata.readthedocs.io/en/latest/base/01_pandas.html#DataFrame-%E5%85%A5%E9%97%A8)
  
## D3
  * [使用Request抓取資料](https://blog.gtwang.org/programming/python-requests-module-tutorial/) 
  * [字串分割](http://www.runoob.com/python/att-string-split.html)
  * [例外處理:Try-Except](https://pydoing.blogspot.com/2011/01/python-try.html)
  * [隨機產生數值](https://blog.csdn.net/christianashannon/article/details/78867204)
  
## D4
  * [Pandas 數據類型](https://blog.csdn.net/claroja/article/details/72622375)

## D5 
  * [敘述統計與機率分佈 by 吳漢銘老師](http://www.hmwu.idv.tw/web/R_AI_M/AI-M1-hmwu_R_Stat&Prob.pdf)
  * 常見的機率分佈 
    * [Standard Statistical Distributions](https://www.healthknowledge.org.uk/public-health-textbook/research-methods/1b-statistical-methods/statistical-distributions])
    * [List of probability distributions](https://en.wikipedia.org/wiki/List_of_probability_distributions)
  * [Descriptive Statistics For pandas Dataframe](https://chrisalbon.com/python/data_wrangling/pandas_dataframe_descriptive_stats/)
  * [pandas 中的繪圖函數](https://amaozhao.gitbooks.io/pandas-notebook/content/pandas%E4%B8%AD%E7%9A%84%E7%BB%98%E5%9B%BE%E5%87%BD%E6%95%B0.html)

## D6
 * [Ways to Detect and Remove the Outliers](https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba)
 * [How to Use Statistics to Identify Outliers in Data](https://machinelearningmastery.com/how-to-use-statistics-to-identify-outliers-in-data/)
 * [ECDF in python without step function?](https://stackoverflow.com/questions/14006520/ecdf-in-python-without-step-function)
 * [ECDF wiki](https://zh.wikipedia.org/wiki/%E7%BB%8F%E9%AA%8C%E5%88%86%E5%B8%83%E5%87%BD%E6%95%B0)

## D7  
 * [Is it a good practice to always scale/normalize data for machine learning?](https://stats.stackexchange.com/questions/189652/is-it-a-good-practice-to-always-scale-normalize-data-for-machine-learning)

## D8
 * [pandas cheat sheet - DataCamp](https://assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf)

## D9
 * [statstutor- 介紹相關係數](http://www.statstutor.ac.uk/resources/uploaded/pearsons.pdf)
 * [guessthecorrelation](http://guessthecorrelation.com/)
 
## D10
 * [核密度估计 Kernel Density Estimation(KDE)](https://blog.csdn.net/unixtch/article/details/78556499)
 * [核密度估计基础-Part I](https://blog.csdn.net/david830_wu/article/details/66974189)

## D11
 * [Python Graph Gallery (圖表參考)](https://python-graph-gallery.com/)

## D12
* [连续特征的离散化](https://www.zhihu.com/question/31989952)

## D14
* [Multiple Subplots](https://jakevdp.github.io/PythonDataScienceHandbook/04.08-multiple-subplots.html)
* [Seaborn jointplot](https://seaborn.pydata.org/generated/seaborn.jointplot.html)

## D17
* [特征工程到底是什么？](https://www.zhihu.com/question/29316149)
* [為什麼特徵工程很重要](https://ithelp.ithome.com.tw/articles/10200041?sc=iThelpR)
* [使用sklearn做单机特征工程](http://www.cnblogs.com/jasonfreak/p/5448385.html)
![](https://ai100-fileentity.cupoy.com/2nd/homework/D17/1556779129615/large)

## D18
* [Built-in Types Python 官方說明](https://docs.python.org/3/library/stdtypes.html)

## D19
* [數據缺失值處理](https://juejin.im/post/5b5c4e6c6fb9a04f90791e0c)
* [数据标准化/归一化](https://blog.csdn.net/pipisorry/article/details/52247379)
![](https://ai100-fileentity.cupoy.com/2nd/homework/D19/1556780749687/large)

## D20
* [離群值](https://zhuanlan.zhihu.com/p/33468998)

## D21
* [偏度與峰度及其python 實現](https://blog.csdn.net/u013555719/article/details/78530879)

## D22
* [數據預處理：獨熱編碼（One-Hot Encoding）和 LabelEncoder標籤編碼](https://www.twblogs.net/a/5baab6e32b7177781a0e6859/zh-cn/)

## D23
* [平均數編碼](https://zhuanlan.zhihu.com/p/26308272)

## D24
* [Feature hashing](https://blog.csdn.net/laolu1573/article/details/79410187)
* [基于sklearn的文本特征抽取](https://www.jianshu.com/p/063840752151)

## D25
* [python-base-datetime](http://www.wklken.me/posts/2015/03/03/python-base-datetime.html)
* [encoding-cyclical-features-for-deep-learning](https://www.kaggle.com/avanwyk/encoding-cyclical-features-for-deep-learning)
* [encoding-cyclical-features-24hour-time](https://ianlondon.github.io/blog/encoding-cyclical-features-24hour-time/)
* [feature-engineering-cyclical-features](http://blog.davidkaleko.com/feature-engineering-cyclical-features.html)

## D26
* [简单高效的组合特征自动挖掘框架](https://zhuanlan.zhihu.com/p/42946318)

## D27 
* [利用python数据分析之数据聚合与分组（七）](https://zhuanlan.zhihu.com/p/27590154)

## D28
* [特征选择](https://zhuanlan.zhihu.com/p/32749489)
* [Feature Selection](https://github.com/htygithub/machine-learning-python/blob/master/Feature_Selection/intro.md)

## D29
* [permutation importance](https://www.kaggle.com/dansbecker/permutation-importance?utm_medium=email&utm_source=mailchimp&utm_campaign=ml4insights)
* [机器学习 - 特征选择算法流程、分类、优化与发展综述](https://juejin.im/post/5a1f7903f265da431c70144c)

##
* [CTR预估[十一]: Algorithm-GBDT Encoder](https://zhuanlan.zhihu.com/p/31734283)
* [Feature transformations with ensembles of trees](https://scikit-learn.org/stable/auto_examples/ensemble/plot_feature_transformation.html#example-ensemble-plot-feature-transformation-py)
* [三分鐘了解推薦系統中的分解機方法（Factorization Machine, FM）](https://kknews.cc/zh-tw/other/62k4rml.html)



## D54
* [Lecture 1.3 — Introduction Unsupervised Learning —  Machine Learning | Andrew Ng](https://www.youtube.com/watch?v=jAA2g9ItoAc)
* [機器學習: 非監督式學習 (Machine Learning: Unsupervised Learning)](https://murphymind.blogspot.com/2017/06/machine-learning-unsupervised-learning.html)

